## Архитектура

### Структура проекта

```
osctl/
├── cmd/
│   └── main.go                    # Точка входа приложения
├── commands/                      # Команды CLI
│   ├── root.go                   # Общие флаги и список команд
│   ├── snapshots.go               # Создание снапшотов
│   ├── snapshot-manual.go        # Ручное создание снапшотов
│   ├── snapshotsdelete.go         # Удаление снапшотов согласно конфигурации
│   ├── indicesdelete.go          # Удаление индексов согласно конфигурации
│   ├── retention.go              # Удаление индексов при превышении порога диска
│   ├── dereplicator.go           # Уменьшение реплик до 0
│   ├── coldstorage.go            # Миграция в cold storage
│   ├── snapshotschecker.go        # Проверка наличия снапшотов
│   ├── snapshotsbackfill.go       # Создание снапшотов для индексов без них
│   ├── danglingchecker.go        # Проверка dangling индексов
│   ├── extracteddelete.go        # Удаление extracted индексов
│   ├── sharding.go               # Автоматическое шардирование
│   ├── indexpatterns.go         # Управление Kibana index patterns
│   └── datasource.go             # Создание Kibana data sources
├── pkg/
│   ├── config/                   # Конфигурация
│   │   ├── config.go            # Основная конфигурация
│   │   ├── osctlindicesconfig.go # Конфигурация индексов
│   │   └── tenantsconfig.go     # Конфигурация тенантов
│   ├── opensearch/              # OpenSearch API клиент
│   │   ├── client.go            # HTTP-клиент
│   │   ├── cluster.go           # allocation, aliases, nodes
│   │   ├── indices.go           # Операции с индексами и их настройками
│   │   ├── snapshots.go         # Работа со снапшотами
│   │   ├── templates.go         # Работа с index templates
│   │   └── tasks.go             # Работа с _tasks API
│   ├── kibana/                  # Kibana API клиент
│   │   ├── client.go            # HTTP-клиент
│   │   └── service.go           # saved objects, data-source
│   ├── alerts/                  # Madison алерты
│   │   └── to_madison.go
│   ├── logging/                 # Логирование
│   │   └── logger.go
│   └── utils/                   # Утилиты
│       ├── date.go              # Действия с датами
│       ├── indices.go           # Работа с индексами
│       ├── snapshots.go         # Работа со снапшотами
│       └── helpers.go           # Вспомогательные функции
├── config-example/                # Примеры конфигураций, job и деплойментов
├── Dockerfile
├── go.mod
├── go.sum
├── config.yaml                      # Единый конфиг
└── README.md
```

## Алгоритмы для каждого флага

### 1. **snapshots** - Создание снапшотов индексов

**Алгоритм:**
1. **Загрузка конфигурации**: Получаем `osctl-indices-config` через `--osctl-indices-config`
2. **Разделение конфигураций**: Разделяем конфигурации на системные (`system: true`) и обычные (`system: false`)
3. **Получение индексов**:
   - **Системные индексы**: `GET /_cat/indices/.*?h=index,ss&bytes=b&s=ss:desc` для всех индексов, начинающихся с точки (только если есть конфигурации с `system: true`)
   - **Обычные индексы**: `GET /_cat/indices/*{yesterday}*?h=index,ss&bytes=b&s=ss:desc` для индексов за вчера (только если есть конфигурации с `system: false`)
4. **Группировка индексов**:
   - Для каждого индекса находим соответствующий конфиг через `FindMatchingIndexConfig`
   - Пропускаем индексы с флагом `manual_snapshot: true`
   - Группируем индексы по паттернам через `AddIndexToSnapshotGroups`, учитывая переопределение репозитория (`Repository` в конфиге)
   - Создаем группы по репозиториям: для каждой группы создается один снапшот
5. **Dry run режим**:
   - Получаем существующие снапшоты за сегодня из целевого репозитория
   - Фильтруем снапшоты со статусом `SUCCESS` - они не показываются в плане
   - Для снапшотов со статусом `IN_PROGRESS` показываем явное сообщение
   - Показываем план создания снапшотов с указанием репозитория для каждой группы
6. **Создание снапшотов**:
   - Ждем завершения всех активных снапшотов через `WaitForSnapshotCompletion` и `WaitForSnapshotTasks`
   - Для каждой группы проверяем существующие снапшоты через `GET /_snapshot/{repo}/*{today}*`
   - Проверяем состояние снапшота через `CheckSnapshotStateInRepo`:
     - Если снапшот уже в состоянии `SUCCESS` - пропускаем с логированием
     - Если снапшот в состоянии `IN_PROGRESS` - пропускаем с логированием
   - Для каждой группы проверяем/удаляем ошибочный снапшот через `CheckAndCleanSnapshot`
   - Создаем снапшот через `CreateSnapshotWithRetry` с retry логикой (до 5 попыток)
   - **Алертинг**: При неудаче после всех попыток отправляется алерт в Madison через `SendSnapshotFailureAlert` (логируется попытка отправки и результат)
   - **Обработка ошибок**: При ошибке создания снапшота команда продолжает работу со следующими снапшотами (не прерывает выполнение)
   - **Repo-specific группы**: Для снапшотов в кастомных репозиториях применяется та же логика создания с retry
7. **Unknown индексы**: Если включено `unknown.snapshot` в конфиге и `manual_snapshot: false`, создаем снапшот "unknown-{date}" в основном репозитории

**Конфигурация:**
- Использует `--osctl-indices-config` для централизованной конфигурации
- Поддерживает prefix и regex паттерны
- Разделяет обработку системных и обычных индексов
- Пропускает индексы с флагом `manual_snapshot: true`
- manual_snapshot используется для ручного исключения из общего потока создания снапов - например для особо огромных идексов - чтобы для них сделать отдельную джобу snapshot-manual
- Поддерживает переопределение репозитория через `Repository` в конфиге индекса

### 2. **snapshot-manual** - Ручное создание снапшотов

**Алгоритм:**
1. **Загрузка параметров**: Получаем параметры индекса через CLI флаги (`--snapshot-manual-kind`, `--snapshot-manual-value`, `--snapshot-manual-name`, `--snapshot-manual-system`, `--snapshot-manual-repo`)
2. **Валидация**: Проверяем обязательные параметры (value, name для regex)
3. **Получение индексов**: 
   - **Системные индексы** (`--snapshot-manual-system`): `GET /_cat/indices/.*?h=index,ss&bytes=b&s=ss:desc` для всех индексов, начинающихся с точки
   - **Обычные индексы** (без `--snapshot-manual-system`): `GET /_cat/indices/*{yesterday}*?h=index,ss&bytes=b&s=ss:desc` для индексов за вчера
4. **Поиск соответствующих индексов**: Находим индексы соответствующие паттерну через `MatchesIndex` с учетом флага `system`
5. **Dry run режим**:
   - Определяем целевой репозиторий: `snapshot-manual-repo` или `snap-repo`
   - Проверяем существующие снапшоты в целевом репозитории
   - Если снапшот со статусом `SUCCESS` уже существует - завершаем без плана
   - Если снапшот со статусом `IN_PROGRESS` - показываем явное сообщение
   - Показываем план создания снапшота с указанием репозитория
6. **Ожидание завершения**: Ждем завершения активных снапшотов через `WaitForSnapshotCompletion` и `WaitForSnapshotTasks` в целевом репозитории
7. **Создание снапшота**:
   - Получаем существующие снапшоты через `GET /_snapshot/{repo}/*{today}*` с обработкой 404
   - Проверяем/удаляем ошибочный снапшот через `CheckAndCleanSnapshot`
   - Создаем снапшот через `CreateSnapshotWithRetry` с retry логикой

**Конфигурация:**
- Использует CLI флаги для параметров одного паттерна индексов
- Поддерживает prefix и regex паттерны
- Учитывает флаг `--snapshot-manual-system` для системных индексов
- Поддерживает переопределение репозитория через `--snapshot-manual-repo`
- Не обрабатывает unknown индексы
- Не использует `--osctl-indices-config`

### 3. **snapshotsdelete** - Удаление снапшотов

**Алгоритм:**
1. **Загрузка конфигурации**: Получаем `osctl-indices-config` и S3 конфигурацию (`unit_count.all`, `unit_count.unknown`)
2. **Получение снапшотов из основного репозитория**: `GET /_snapshot/{repo}/*` для всех снапшотов из основного репозитория
3. **Фильтрация снапшотов основного репозитория**:
   - Для каждого снапшота находим соответствующий конфиг через `FindMatchingSnapshotConfig`
   - Если снапшот имеет переопределенный репозиторий (`Repository` в конфиге) - пропускаем его (такие снапшоты обрабатываются отдельно в кастомных репозиториях)
   - Если конфиг найден и `snapshot: true`:
     - Используем `snapshot_count_s3` из конфига или `unit_count.all` из S3 конфига как количество дней
     - Проверяем возраст через `IsOlderThanCutoff`
   - Если конфиг не найден:
     - Если снапшот имеет дату в названии - добавляем в `unknownSnapshots`
     - Если снапшота нет даты в названии - добавляем в `danglingSnapshots` (логируем, но не удаляем)
4. **Unknown снапшоты**: Если включено `unknown.snapshot`, применяем `unit_count.unknown` для снапшотов без конфига, но с датой в названии
5. **Обработка переопределенных репозиториев**:
   - Собираем все уникальные репозитории из конфигов, где `Repository != ""` и `snapshot: true`
   - Для каждого кастомного репозитория:
     - Получаем все снапшоты через `GET /_snapshot/{repo}/*`
     - Для каждого снапшота находим соответствующий конфиг через `FindMatchingSnapshotConfig`
     - Проверяем, что снапшот **точно соответствует** паттерну или регексу в конфиге:
       - Конфиг должен быть найден (`ic != nil`)
       - Репозиторий в конфиге должен совпадать с текущим репозиторием (`ic.Repository == repo`)
       - В конфиге должно быть `snapshot: true`
     - Если снапшот не соответствует - логируем как "dangling" и пропускаем
     - Если снапшот соответствует, но не имеет даты в названии - пропускаем с логированием
     - Если снапшот соответствует и имеет дату - проверяем возраст:
       - Используем `snapshot_count_s3` из конфига или `unit_count.all` из S3 конфига
       - Если снапшот старше - добавляем в список для удаления из этого репозитория
6. **Dry run режим**: Показываем список снапшотов для удаления, группируя по репозиториям
7. **Удаление**: Через `DeleteSnapshotsBatch` с группировкой по репозиториям (основной и кастомные)

**Примечания:**
- Никогда не трогаем снапшоты без даты в нужном формате старше чем Unknown политика, но выводим их в лог
- Снапшоты в переопределенных репозиториях обрабатываются только если они **точно соответствуют** паттерну или регексу в конфиге и находятся в правильном репозитории
- Снапшоты из основного репозитория, у которых в конфиге указан переопределенный репозиторий, не обрабатываются (они должны обрабатываться в своем кастомном репозитории)

### 4. **indicesdelete** - Удаление индексов

**Алгоритм:**
1. **Загрузка конфигурации**: Получаем `osctl-indices-config` и `unknown.days_count`
2. **Получение индексов**: `GET /_cat/indices/*?h=index,cd&bytes=b&s=index:asc` для всех индексов
3. **Фильтрация индексов**:
   - Пропускаем системные индексы (начинающиеся с `.`)
   - Пропускаем extracted индексы (начинающиеся с `extracted_`)
   - Для каждого индекса находим соответствующий конфиг через `FindMatchingIndexConfig`
   - Если конфиг найден:
     - Если индекс имеет дату в названии - проверяем возраст через `IsOlderThanCutoff` с `days_count` из конфига
     - Если у индекса нет даты в названии - просто логируем (не проверяем возраст, не удаляем)
   - Если конфиг не найден:
     - Если индекс имеет дату в названии - добавляем в `unknownIndices` для дальнейшей обработки
     - Если у индекса нет даты в названии - просто логируем (не проверяем возраст, не добавляем в unknown, не удаляем)
4. **Фильтрация unknown индексов**: Применяем `FilterUnknownIndices` для исключения известных паттернов (только для индексов с датой в названии)
5. **Обработка unknown индексов**: Для каждого отфильтрованного unknown индекса (только с датой в названии):
   - Если `unknown.days_count > 0` и индекс старше cutoff - добавляем в список для удаления
6. **Dry run режим**: Показываем список индексов для удаления
7. **Удаление**: Через `DeleteIndicesBatch` с dry run поддержкой

**Примечания:**
- Никогда не удаляем системные индексы (начинающиеся с `.`)
- Никогда не трогаем индексы без даты в нужном формате старше чем Unknown политика, но выводим их в лог

### 5. **retention** - Удаление индексов по утилизации диска

**Алгоритм:**
1. **Расчёт утилизации**: Получаем `GET /_cat/allocation`, считаем среднюю утилизацию по всем нодам
2. **Если утилизация <= порога**: Завершаем выполнение
3. **Получение кандидатов**:
   - Получаем индексы через `GET /_cat/indices/*,-.*,-*{today},-*{yesterday},-extracted_*?h=index,ss&bytes=b&s=ss:desc`
   - Исключаем системные индексы, индексы за сегодня, за вчера и extracted индексы
   - Сортируем по размеру (убывание)
4. **Проверка снапшотов**: Получаем все снапшоты через `GET /_snapshot/{snap_repo}/*`
5. **Dry run режим**: Показываем первые 5 индексов для удаления с их размерами
6. **Удаление индексов**:
   - Для каждого индекса в порядке убывания размера:
     - Если утилизация уже <= порога - прекращаем удаление
     - Проверяем наличие валидного снапшота через `HasValidSnapshot`
     - Если снапшота нет - пропускаем индекс с предупреждением
     - Если валидный снапшот найден - логируем факт проверки
   - **Удаление с проверкой порога**:
     - Для каждого индекса с валидным снапшотом:
       - Удаляем индекс через `DELETE /{index}`
       - После каждого удаления делаем паузу 15 секунд
       - Пересчитываем утилизацию через `GET /_cat/allocation`
       - **Останавливаем удаление**, если утилизация стала меньше или равна порогу

**Конфигурация:**
- Требует `--snap-repo` для проверки снапшотов
- Использует `--retention-threshold` для порога утилизации (по умолчанию 75%)

### 6. **dereplicator** - Уменьшение реплик старых индексов

**Алгоритм:**
1. **Получение индексов**: `GET /_cat/indices/*?h=index,rep` для всех индексов
2. **Фильтрация по возрасту**: Для каждого индекса проверяем:
   - Индекс не системный (не начинается с `.`)
   - Индекс имеет реплики > 0
   - Индекс старше `--dereplicator-days-count` дней через `IsOlderThanCutoff`
3. **Проверка snapshots** (если `--dereplicator-use-snapshot`):
   - Требуется `--snap-repo`
   - Получаем все snapshots через `GET /_snapshot/{snap_repo}/*`
   - Проверяем наличие валидного снапшота через `HasValidSnapshot`
   - Если снапшота нет - пропускаем индекс с предупреждением
4. **Dry run режим**: Показываем список индексов, для которых будут установлены реплики 0
5. **Установка 0 реплик**: Через `PUT /{index}/_settings` с body `{"index":{"number_of_replicas":0}}`

**Конфигурация:**
- Использует `--dereplicator-days-count` для количества дней (по умолчанию 2)
- Опционально использует `--dereplicator-use-snapshot` для проверки снапшотов перед уменьшением реплик

### 7. **coldstorage** - Миграция в cold storage

**Алгоритм:**
1. **Получение индексов**: `GET /_cat/indices/*?h=index` для всех индексов
2. **Фильтрация по возрасту**: Индексы старше `--hot-count` дней через `IsOlderThanCutoff`
3. **Проверка текущего состояния**:
   - Для каждого кандидата получаем текущий `routing.allocation.require.temp` через `GET /{index}/_settings`
   - Если индекс уже имеет требуемый атрибут - пропускаем с логированием
4. **Dry run режим**: Показываем список индексов для миграции
5. **Перемещение в cold**: Через `PUT /{index}/_settings` с allocation settings:
   ```json
   {
     "index": {
       "routing.allocation.require.temp": "{cold-attribute}",
       "number_of_replicas": 0
     }
   }
   ```

**Конфигурация:**
- Использует `--hot-count` для количества дней в hot (по умолчанию 4)
- Использует `--cold-attribute` для атрибута cold нод (по умолчанию "cold")

### 8. **snapshotschecker** - Проверка наличия снапшотов

**Алгоритм:**
1. **Загрузка конфигурации**: Получаем `osctl-indices-config`, `unknown.snapshot` и S3 конфигурацию (`unit_count.all`, `unit_count.unknown`)
2. **Получение всех индексов**: `GET /_cat/indices/*?h=index` для всех индексов
3. **Фильтрация индексов**:
   - Пропускаем системные индексы (начинающиеся с `.`) и extracted индексы через `ShouldSkipIndex`
   - Пропускаем индексы без даты в названии
   - Исключаем индексы за сегодня и вчера
   - Остальные индексы (за позавчерашний день и старше) добавляем в список для обработки
4. **Проверка снапшотов**: Получаем все снапшоты через `GET /_snapshot/{repo}/*`
5. **Определение индексов без снапшотов с учетом cutoff даты**:
   - Для каждого индекса находим соответствующий конфиг через `FindMatchingIndexConfig`
   - Если конфиг найден:
     - Проверяем `snapshot: true` и `manual_snapshot: false`
     - Определяем cutoff дату: используем наименьшую (ближайшую к настоящему) из `days_count` и `snapshot_count_s3`/`s3_snapshots.unit_count.all` через `GetLaterCutoffDate`
     - Если индекс старше cutoff - пропускаем с логированием
     - Если индекс не старше cutoff - проверяем наличие валидного снапшота через `HasValidSnapshot`
     - Если снапшота нет - добавляем в список проблемных индексов
   - Если конфиг не найден:
     - Если включен `unknown.snapshot` и `manual_snapshot: false`:
       - Определяем cutoff дату для unknown: используем наименьшую из `unknown.days_count` и `s3_snapshots.unit_count.unknown` через `GetLaterCutoffDate`
       - Если индекс старше cutoff - пропускаем с логированием
       - Если индекс не старше cutoff - проверяем наличие валидного снапшота
       - Если снапшота нет - добавляем в список проблемных индексов
6. **Dry run режим**: Только логирование отсутствующих снапшотов, алерты не отправляются
7. **Алерт в Madison**: Если найдены отсутствующие снапшоты и не dry run - отправляем через `SendMadisonSnapshotMissingAlert` со списком всех проблемных индексов

**Конфигурация:**
- Требует `--osctl-indices-config`
- Использует `--snap-repo` для проверки снапшотов
- Использует `unknown.snapshot` для включения unknown индексов
- Учитывает `days_count` и `snapshot_count_s3` из конфига индексов
- Учитывает `s3_snapshots.unit_count.all` и `s3_snapshots.unit_count.unknown` из S3 конфига
- Использует cutoff дату (наименьшую из `days_count` и S3 дней) для определения, какие индексы должны иметь снапшоты

### 9. **snapshotsbackfill** - Создание снапшотов для индексов без снапшотов

**Алгоритм:**

**Режим 1: С параметром `--indices-list`**
1. **Загрузка конфигурации**: Получаем `osctl-indices-config`, `unknown.snapshot` и S3 конфигурацию
2. **Получение списка индексов**: Парсим `--indices-list` (список через запятую)
3. **Фильтрация индексов**:
   - Для каждого индекса проверяем наличие даты в названии через `HasDateInName`
   - Если даты нет - пропускаем с логированием предупреждения
   - Если дата есть - добавляем в список для обработки
4. **Проверка снапшотов**: Получаем все снапшоты через `GET /_snapshot/{repo}/*`
5. **Определение индексов без снапшотов**: Для каждого индекса проверяем наличие валидного снапшота через `HasValidSnapshot`
6. **Группировка по датам**: Группируем индексы без снапшотов по датам (по убыванию даты)
7. **Создание снапшотов**: Для каждой группы по датам создаем снапшоты (алгоритм создания ниже)

**Режим 2: Без параметра `--indices-list`**
1. **Загрузка конфигурации**: Получаем `osctl-indices-config`, `unknown.snapshot` и S3 конфигурацию
2. **Получение всех индексов**: `GET /_cat/indices/*?h=index` для всех индексов
3. **Фильтрация по датам**:
   - Включаем индексы за позавчерашний день и все более старые
   - Пропускаем индексы без даты в названии
4. **Проверка снапшотов**: Получаем все снапшоты через `GET /_snapshot/{repo}/*`
5. **Определение индексов без снапшотов**: Для каждого индекса проверяем наличие валидного снапшота через `HasValidSnapshot`
6. **Группировка по датам**: Группируем индексы без снапшотов по датам (по убыванию даты)
7. **Создание снапшотов**: Для каждой группы по датам создаем снапшоты (алгоритм создания ниже)

**Алгоритм создания снапшотов для группы по дате:**
1. **Разделение конфигураций**: Разделяем конфигурации на системные и обычные
2. **Обработка индексов**:
   - Для каждого индекса находим соответствующий конфиг через `FindMatchingIndexConfig`
   - Если конфиг найден:
     - Проверяем `snapshot: true` и `manual_snapshot: false`
     - Определяем cutoff дату: используем `snapshot_count_s3` из конфига, если есть, иначе `s3_snapshots.unit_count.all` из S3 конфига, иначе `days_count` из конфига, но если snapshot_count_s3 или s3_snapshots.unit_count.all более ранние - берем их
     - Если индекс старше cutoff - пропускаем с логированием
     - Добавляем индекс в группы через `AddIndexToSnapshotGroups` (учитывая переопределение репозитория)
   - Если конфиг не найден - добавляем в `unknownIndices`
3. **Фильтрация unknown индексов**: Применяем `FilterUnknownIndices` и проверяем cutoff для unknown (используем наиболее ранний из `s3_snapshots.unit_count.unknown` или `unknown.days_count`)
4. **Группировка для снапшотов**: Группируем индексы через `GroupIndicesForSnapshots`
5. **Dry run режим**:
   - Получаем существующие снапшоты за дату из целевого репозитория
   - Фильтруем снапшоты со статусом `SUCCESS` и `IN_PROGRESS`
   - Показываем план создания снапшотов с указанием репозитория для каждой группы
6. **Создание снапшотов**:
   - Для каждой группы проверяем существующие снапшоты через `GET /_snapshot/{repo}/*{date}*`
   - Проверяем состояние снапшота через `CheckSnapshotStateInRepo`:
     - Если снапшот уже в состоянии `SUCCESS` - пропускаем с логированием
     - Если снапшот в состоянии `IN_PROGRESS` - пропускаем с логированием
   - Для каждой группы проверяем/удаляем ошибочный снапшот через `CheckAndCleanSnapshot`
   - Создаем снапшот через `CreateSnapshotWithRetry` с retry логикой
   - **Пауза**: После каждого создания снапшота делаем паузу 10 минут перед следующим
   - **Алертинг**: При неудаче после всех попыток отправляется алерт в Madison
   - **Обработка ошибок**: При ошибке создания снапшота команда продолжает работу со следующими снапшотами
   - **Repo-specific группы**: Для снапшотов в кастомных репозиториях применяется та же логика создания с retry и паузой 10 минут

**Конфигурация:**
- Использует `--osctl-indices-config` для централизованной конфигурации
- Поддерживает prefix и regex паттерны
- Пропускает индексы с флагом `manual_snapshot: true`
- Поддерживает переопределение репозитория через `Repository` в конфиге индекса
- Учитывает `days_count` и `snapshot_count_s3` из конфига индексов
- Учитывает `s3_snapshots.unit_count.all` и `s3_snapshots.unit_count.unknown` из S3 конфига
- Использует `unknown.snapshot` для включения unknown индексов

### 10. **danglingchecker** - Проверка dangling индексов

**Алгоритм:**
1. **Запрос dangling**: `GET /_dangling?pretty` для получения списка dangling индексов
2. **Если найдены**: 
   - Извлекаем имена индексов из ответа
   - Логируем найденные dangling индексы
3. **Dry run режим**: Только логирование найденных индексов, алерты не отправляются
4. **Алерт в Madison**: Если найдены dangling индексы и не dry run - отправляем через `SendMadisonDanglingIndicesAlert`

**Конфигурация:**
- Требует `--madison-key`, `--osd-url` и `--madison-url` для отправки алертов

### 11. **extracteddelete** - Удаление extracted индексов

**Алгоритм:**
1. **Подключение к Recoverer**: Используется `--os-recoverer-url` для подключения к OpenSearch Recoverer (не к основному кластеру)
2. **Получение индексов**: `GET /_cat/indices/{extracted_pattern}*?h=index` для всех extracted индексов (по умолчанию `extracted_`)
3. **Фильтрация по возрасту**: Индексы старше `--days` дней через `IsOlderThanCutoff` с использованием `--recoverer-date-format` (по умолчанию `%d-%m-%Y`)
4. **Dry run режим**: Показываем список extracted индексов для удаления
5. **Удаление**: Через `DELETE /{index}` для каждого подходящего индекса

**Конфигурация:**
- Использует `--os-recoverer-url` для подключения к Recoverer (по умолчанию `https://opendistro-recoverer:9200`)
- Использует `--extracted-pattern` для префикса extracted индексов (по умолчанию `extracted_`)
- Использует `--days` для количества дней хранения (по умолчанию 7)
- Использует `--recoverer-date-format` для формата даты в названиях extracted индексов (по умолчанию `%d-%m-%Y`)

### 12. **sharding** - Автоматическое шардирование

**Алгоритм:**

1. **Получение всех индексов**: `GET /_cat/indices/*?h=index,pri.store.size&bytes=b` - получаем все индексы с primary store size (без учета реплик) для вычисления максимального размера паттерна
2. **Получение индексов за сегодня**: `GET /_cat/indices/*-{today}*,-.*?h=index,pri.store.size&bytes=b&s=pri.store.size:desc` - получаем индексы за сегодня, отсортированные по размеру
3. **Группировка по паттернам**:
   - Для каждого индекса за сегодня определяем базовый паттерн: удаляем дату и все что после нее (включая суффиксы типа `-00`, `-01`)
   - Определяем является ли индекс почасовым (имеет суффикс после даты)
   - Группируем индексы по базовому паттерну: `{base}-*`
   - Для каждого паттерна находим максимальный размер среди всех индексов с этим паттерном
4. **Вычисление максимального размера паттерна**:
   - Для каждого паттерна ищем все индексы с префиксом `{base}-`
   - Игнорируем все что после даты в названии индекса
   - Находим максимальный primary store size среди всех индексов паттерна
   - Используем размер сегодняшнего индекса как начальное значение
5. **Получение количества data нод**: `GET /_cat/nodes?h=node.role&s=name` - считаем ноды с ролью `data` (не master, не cold)
6. **Расчёт количества шардов**: 
   - `shards_needed = max_size / target_size_gib + 1`
   - Если `shards_needed > dataNodes` - ограничиваем `shards_needed = dataNodes`
   - Минимум 1 шард
7. **Расчёт реплик**:
   - Если `dataNodes <= 1` - устанавливаем `replicas = 0`
   - Иначе - устанавливаем `replicas = 1`
8. **Вычисление приоритета**: `priority = количество_дефисов_в_паттерне * 1000`
9. **Проверка существующего шаблона**: 
   - Нормализуем паттерн (удаляем `*` и trailing `-`)
   - Ищем существующий шаблон через `FindIndexTemplateByPattern`
10. **Dry run режим**:
    - Если шаблон существует: показываем изменение `number_of_shards` (если отличается)
    - Если шаблона нет: показываем создание нового шаблона
    - Выводим summary со всеми изменениями
11. **Обновление существующего шаблона**:
    - Получаем существующий шаблон через `GET /_index_template/{name}`
    - Сохраняем шаблон "как есть", изменяем только:
      - `template.settings.index.number_of_shards` на рассчитанное значение
      - `template.settings.index.query.default_field` на `["message","text","log","original_message"]`
    - Если установлен `--sharding-routing-allocation-temp` - обновляем `template.settings.index.routing.allocation.require.temp`
    - Отправляем обновленный шаблон через `PUT /_index_template/{name}`
12. **Создание нового шаблона**:
    - Имя шаблона: `{base}-sharding`
    - Настройки индекса:
      - `number_of_shards`: рассчитанное количество
      - `number_of_replicas`: рассчитанное количество (0 или 1)
      - `mapping.total_fields.limit`: 2000
      - `query.default_field`: `["message","text","log","original_message"]`
      - Если установлен `--sharding-routing-allocation-temp` - добавляем `routing.allocation.require.temp`
    - Если индекс почасовой (имеет суффикс после даты) - добавляем `composed_of: ["default_template"]`
    - Приоритет: рассчитанное значение
    - Отправляем через `PUT /_index_template/{name}`

**Конфигурация:**
- Использует `--sharding-target-size-gib` для целевого размера шарда (по умолчанию 25, максимум 50 GiB)
- Использует `--exclude-sharding` для regex исключения паттернов
- Использует `--sharding-routing-allocation-temp` для установки `routing.allocation.require.temp` (например, "hot")
- Игнорирует системные индексы (начинающиеся с `.`)

### 13. **indexpatterns** - Управление Kibana index patterns

**Алгоритм (multitenancy):**

1. **Загрузка конфигурации тенантов**: Получаем `--indexpatterns-kibana-tenants-config` (по умолчанию `osctltenants.yaml`)
2. **Для каждого тенанта**:
   - Нормализуем имя тенанта: удаляем дефисы через `NormalizeTenantName`
   - Ищем индекс тенанта через `GET /_cat/aliases/.kibana*_{normalized_tenant}`
   - Если индекс не найден - пропускаем тенант
   - Получаем существующие index patterns через `GET /{tenant_index}/_search?q=type:index-pattern`
   - Извлекаем `title` из существующих patterns
3. **Определение паттернов для создания**:
   - Загружаем паттерны из конфига тенанта (`indices` в YAML)
   - Удаляем дубликаты через `seen` map
   - Для каждого паттерна проверяем существование в текущих patterns
   - Если паттерна нет - добавляем в список для создания
4. **Dry run режим**: Показываем список паттернов для создания в каждом тенанте
5. **Создание patterns**:
   - Для каждого паттерна создаем документ типа `index-pattern` через `POST /{tenant_index}/_doc/index-pattern:{uuid}`
   - Устанавливаем `title` в паттерн и `timeFieldName` в `@timestamp`

**Алгоритм (без multitenancy):**

1. **Загрузка regex**: Получаем `--kibana-index-regex` (обязательно в single-tenant режиме)
2. **Получение индексов за сегодня**: `GET /_cat/indices/*-{today}*,-.*?h=index&s=i` для индексов за сегодня
3. **Построение паттернов**: 
   - Применяем regex к каждому индексу
   - Извлекаем базовый паттерн через первую группу захвата regex
   - Формируем паттерн: `{base}-*`
   - Удаляем дубликаты
4. **Получение существующих patterns**: `GET /{tenant_index}/_search?q=type:index-pattern` из `.kibana`
5. **Создание недостающих patterns**: Для каждого отсутствующего паттерна создаем через `POST /{tenant_index}/_doc/index-pattern:{uuid}`
6. **Создание extracted_* pattern** (если `--indexpatterns-recoverer-enabled`):
   - Создаем паттерн `extracted_*` с ссылкой на data-source через `references`

**Конфигурация:**
- Использует `--indexpatterns-kibana-multitenancy` для переключения режима
- Использует `--indexpatterns-kibana-tenants-config` для пути к конфигу тенантов
- Использует `--kibana-index-regex` для построения паттернов в single-tenant режиме
- Использует `--indexpatterns-recoverer-enabled` для создания `extracted_*` pattern (только в single-tenant режиме)
- `extracted_*` по соображениям безопасности не создается в режиме multitenancy

### 14. **datasource** - Создание Kibana data sources

**Алгоритм:**

1. **Валидация параметров**: Проверяем `--datasource-name`, `--os-url` и `--osd-url` (обязательны)
2. **Нормализация URL**: Добавляем схему `https://` к `osd-url` если отсутствует через `NormalizeURL`
3. **Определение списка тенантов**:
   - Если `--datasource-kibana-multitenancy` - загружаем тенанты из `--kibana-tenants-config` (общий флаг, не `datasource-kibana-tenants-config`)
   - Всегда добавляем "global" тенант
4. **Для каждого тенанта**:
   - Получаем существующие data sources через `GET /api/saved_objects/_find?type=data-source&securitytenant={tenant}` (используем оригинальное имя тенанта с дефисами)
   - Проверяем наличие data source с нужным названием
   - Если не существует - создаем через `POST /api/saved_objects/data-source` с basic auth
5. **Multidomain режим** (если `--datasource-kibana-multidomain-enabled`):
   - Декодируем `--datasource-remote-crt` (base64 строки, разделенные `|`)
   - Получаем `ca.crt` из Kubernetes секрета `recoverer-certs` в namespace `--kube-namespace`
   - Конкатенируем все сертификаты
   - Проверяем существование секрета `multi-certs` в Kubernetes
   - Если секрет существует - сравниваем содержимое `multi.crt`
   - Если содержимое отличается или секрета нет - обновляем/создаем секрет
   - Если секрет был обновлен - перезапускаем Kibana deployment (требуется доступ к Kubernetes API)
6. **Dry run режим**: Показываем план создания/обновления data sources и секретов без выполнения

**Конфигурация:**
- Использует `--datasource-name` для названия data source (по умолчанию "recoverer")
- Использует `--kibana-user` и `--kibana-pass` для basic auth
- Использует `--kube-namespace` для namespace Kubernetes секретов (по умолчанию "infra-elklogs")
- Использует `--datasource-kibana-multitenancy` для включения multitenancy
- Использует `--datasource-kibana-multidomain-enabled` для управления multidomain сертификатами
- Использует `--datasource-remote-crt` для удаленных сертификатов (base64, разделенные `|`)
- Использует общий флаг `--kibana-tenants-config` для загрузки тенантов (не `datasource-kibana-tenants-config`)

### Приоритет конфигурации

1. **CLI флаги** (высший приоритет)
2. **Переменные окружения**
3. **Файлы конфигурации** (`config.yaml`)
4. **Файл конфигурации индексов** (`osctlindicesconfig.yaml`) - для команд `snapshots`, `indicesdelete`, `snapshotsdelete`, `snapshotschecker`
5. **Значения по умолчанию** (низший приоритет)
